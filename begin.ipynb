{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452ad336",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import playwright\n",
    "import jmespath\n",
    "from playwright.sync_api import sync_playwright\n",
    "from twikit import Client\n",
    "import json\n",
    "import transformers\n",
    "import sentencepiece\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ab13aa",
   "metadata": {},
   "source": [
    "The command to use in order to have access to a tweet with its id is :\n",
    "\n",
    "``twitter.com/anyuser/status/541278904204668929\n",
    "``\n",
    "With 541278904204668929 being an example of a tweet's id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbacd70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/patriChiril/An-Annotated-Corpus-for-Sexism-Detection-in-French-Tweets/refs/heads/master/corpus_SexistContent.csv'\n",
    "df_base = pd.read_csv(url, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207a22e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base.columns = ['id','label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69825deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base.to_csv('data_id.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786cc0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://docs.google.com/spreadsheets/d/1eoC3NooDOwFoOvfweVLEZ-z-jCPZghUCVMUPTBkUDIk/export?format=csv&gid=1834088666'\n",
    "df_whole = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6626f46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_whole.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0dd4e8",
   "metadata": {},
   "source": [
    "### Model's import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449faf59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import CamembertModel, CamembertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25fc598",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_str = 'tarte au prout et au caca'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5627f3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import CamembertModel, CamembertTokenizer\n",
    "\n",
    "# You can replace \"camembert-base\" with any other model from the table, e.g. \"camembert/camembert-large\".\n",
    "tokenizer = CamembertTokenizer.from_pretrained(\"camembert/camembert-base-wikipedia-4gb\")\n",
    "camembert = CamembertModel.from_pretrained(\"camembert/camembert-base-wikipedia-4gb\")\n",
    "\n",
    "camembert.eval()  # disable dropout (or leave in train mode to finetune)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6f7ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_sentence = tokenizer.tokenize('tarte au caca')\n",
    "encoded_sentence = tokenizer.encode(tokenized_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52dd07b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_sentence = torch.tensor(encoded_sentence).unsqueeze(0)\n",
    "embeddings, _ = camembert(encoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b380e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf3ba85-b88f-4b6b-8c98-b88f53a4e158",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_sentence = tokenizer.encode(tokenized_sentence)\n",
    "# [5, 221, 10, 10600, 14, 8952, 10540, 75, 1114, 6]\n",
    "# NB: Can be done in one step : tokenize.encode(\"J'aime le camembert !\")\n",
    "\n",
    "# Feed tokens to Camembert as a torch tensor (batch dim 1)\n",
    "encoded_sentence = torch.tensor(encoded_sentence).unsqueeze(0)\n",
    "embeddings, _ = camembert(encoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af27e977-9d39-43a8-baeb-fc2a0e270bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bb46d6-00fb-409b-8ee5-3a252b183500",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# Tokenize in sub-words with SentencePiece\n",
    "tokenized_sentence = tokenizer.tokenize(\"J'aime le camembert !\")\n",
    "# ['▁J', \"'\", 'aime', '▁le', '▁ca', 'member', 't', '▁!'] \n",
    "\n",
    "# 1-hot encode and add special starting and end tokens \n",
    "encoded_sentence = tokenizer.encode(tokenized_sentence)\n",
    "# [5, 221, 10, 10600, 14, 8952, 10540, 75, 1114, 6]\n",
    "# NB: Can be done in one step : tokenize.encode(\"J'aime le camembert !\")\n",
    "\n",
    "# Feed tokens to Camembert as a torch tensor (batch dim 1)\n",
    "encoded_sentence = torch.tensor(encoded_sentence).unsqueeze(0)\n",
    "embeddings, _ = camembert(encoded_sentence)\n",
    "# embeddings.detach()\n",
    "# embeddings.size torch.Size([1, 10, 768])\n",
    "#tensor([[[-0.0928,  0.0506, -0.0094,  ..., -0.2388,  0.1177, -0.1302],\n",
    "#         [ 0.0662,  0.1030, -0.2355,  ..., -0.4224, -0.0574, -0.2802],\n",
    "#         [-0.0729,  0.0547,  0.0192,  ..., -0.1743,  0.0998, -0.2677],\n",
    "#         ...,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e91e85-6d5f-44a6-934d-20334a7fa051",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec11ebee-ab74-4364-8452-6859c9ec2756",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import CamembertModel, CamembertTokenizer\n",
    "\n",
    "# You can replace \"camembert-base\" with any other model from the table, e.g. \"camembert/camembert-large\".\n",
    "tokenizer = CamembertTokenizer.from_pretrained(\"camembert/camembert-base-wikipedia-4gb\")\n",
    "camembert = CamembertModel.from_pretrained(\"camembert/camembert-base-wikipedia-4gb\")\n",
    "\n",
    "camembert.eval()  # disable dropout (or leave in train mode to finetune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d00b3cd-3b1e-4a34-a5bd-5de76aa855a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# Tokenize in sub-words with SentencePiece\n",
    "tokenized_sentence = tokenizer.tokenize(\"J'aime le camembert !\")\n",
    "# ['▁J', \"'\", 'aime', '▁le', '▁ca', 'member', 't', '▁!'] \n",
    "\n",
    "# 1-hot encode and add special starting and end tokens \n",
    "encoded_sentence = tokenizer.encode(tokenized_sentence)\n",
    "# [5, 221, 10, 10600, 14, 8952, 10540, 75, 1114, 6]\n",
    "# NB: Can be done in one step : tokenize.encode(\"J'aime le camembert !\")\n",
    "\n",
    "# Feed tokens to Camembert as a torch tensor (batch dim 1)\n",
    "encoded_sentence = torch.tensor(encoded_sentence).unsqueeze(0)\n",
    "embeddings, _ = camembert(encoded_sentence)\n",
    "# embeddings.detach()\n",
    "# embeddings.size torch.Size([1, 10, 768])\n",
    "#tensor([[[-0.0928,  0.0506, -0.0094,  ..., -0.2388,  0.1177, -0.1302],\n",
    "#         [ 0.0662,  0.1030, -0.2355,  ..., -0.4224, -0.0574, -0.2802],\n",
    "#         [-0.0729,  0.0547,  0.0192,  ..., -0.1743,  0.0998, -0.2677],\n",
    "#         ...,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e255ebf-2479-427f-b6d4-fe53ee440cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e852159e-3838-42fe-ae7f-22f8158c208e",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70507812-62cc-414f-8df8-bb7a95b1150c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import CamembertTokenizer, CamembertModel\n",
    "\n",
    "# Load CamemBERT model and tokenizer\n",
    "tokenizer = CamembertTokenizer.from_pretrained(\"camembert-base\")\n",
    "model = CamembertModel.from_pretrained(\"camembert-base\")\n",
    "\n",
    "# Input sentence\n",
    "sentence = \"J'aime le camembert !\"\n",
    "\n",
    "# Tokenize and convert to PyTorch tensors\n",
    "inputs = tokenizer(sentence, return_tensors=\"pt\", return_attention_mask=True)\n",
    "\n",
    "# Forward pass (no gradients needed)\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "# Get token embeddings from last hidden state: [1, seq_len, 768]\n",
    "last_hidden_state = outputs.last_hidden_state\n",
    "\n",
    "# Decode tokens to match embeddings with actual text tokens\n",
    "tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])\n",
    "\n",
    "# Print token-wise embeddings\n",
    "for idx, token in enumerate(tokens):\n",
    "    embedding = last_hidden_state[0, idx]  # shape: [768]\n",
    "    print(f\"Token: {token}\\nEmbedding: {embedding.tolist()[:5]}...\")  # first 5 dims for brevity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e631afd1-9152-4c7b-96d5-c88c76bc0499",
   "metadata": {},
   "source": [
    "Exemple de bite en bois de merde : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9570244-9830-4815-96f9-f5a0e5136232",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import CamembertTokenizerFast, CamembertModel\n",
    "tokenizer = CamembertTokenizerFast.from_pretrained(\"camembert-base\")\n",
    "\n",
    "\n",
    "# Set device (GPU if available)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load model and tokenizer\n",
    "tokenizer = CamembertTokenizerFast.from_pretrained(\"camembert-base\")\n",
    "model = CamembertModel.from_pretrained(\"camembert-base\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Sample DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'text': [\n",
    "        \"J'aime le camembert !\",\n",
    "        \"Les chats dorment sur le canapé.\",\n",
    "        \"Il pleut souvent à Paris.\"\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Tokenize and batch the text\n",
    "inputs = tokenizer(\n",
    "    df['text'].tolist(),\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    return_tensors='pt',\n",
    "    return_attention_mask=True,\n",
    "    return_offsets_mapping=True,\n",
    "    add_special_tokens=True\n",
    ")\n",
    "\n",
    "# Move inputs to GPU\n",
    "input_ids = inputs['input_ids'].to(device)\n",
    "attention_mask = inputs['attention_mask'].to(device)\n",
    "\n",
    "# Run model on GPU\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "# Get token embeddings (last hidden state)\n",
    "token_embeddings = outputs.last_hidden_state  # shape: [batch_size, seq_len, 768]\n",
    "\n",
    "# Optionally move embeddings back to CPU\n",
    "token_embeddings_cpu = token_embeddings.cpu()\n",
    "\n",
    "# Convert input IDs to tokens\n",
    "batch_tokens = [\n",
    "    tokenizer.convert_ids_to_tokens(seq_ids) for seq_ids in input_ids.cpu()\n",
    "]\n",
    "\n",
    "# Display tokens and their embeddings (first 3 dimensions shown for brevity)\n",
    "for i, tokens in enumerate(batch_tokens):\n",
    "    print(f\"\\nSentence {i + 1}:\")\n",
    "    for j, token in enumerate(tokens):\n",
    "        vector = token_embeddings_cpu[i, j]\n",
    "        print(f\"  Token: {token.ljust(12)} Embedding: {vector[:3].tolist()}...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a6aada-7bd8-48ff-b6cd-192f5281baf5",
   "metadata": {},
   "source": [
    "Exemple de retrain a la con de merde : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d1b380-7959-402e-87bc-9b99a7c9a3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import CamembertModel\n",
    "\n",
    "class CamembertSentenceClassifier(nn.Module):\n",
    "    def __init__(self, hidden_dim=768, mid_dim=256, dropout=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        # Load pre-trained CamemBERT\n",
    "        self.bert = CamembertModel.from_pretrained(\"camembert-base\")\n",
    "        \n",
    "        # Freeze all BERT parameters\n",
    "        for param in self.bert.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # Classification head (only this is trainable)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, mid_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(mid_dim, 1),      # Binary classification\n",
    "            nn.Sigmoid()                # Output in [0, 1]\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        with torch.no_grad():\n",
    "            outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        # Use mean pooling over token embeddings to get sentence representation\n",
    "        token_embeddings = outputs.last_hidden_state       # [batch_size, seq_len, 768]\n",
    "        pooled = token_embeddings.mean(dim=1)              # [batch_size, 768]\n",
    "\n",
    "        # Classifier outputs probability\n",
    "        return self.classifier(pooled)                     # [batch_size, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff096aa1-9d1f-4049-acf5-2924234c73f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate model\n",
    "model = CamembertSentenceClassifier()\n",
    "model.to(device)\n",
    "\n",
    "# Optimizer (only train classifier parameters)\n",
    "optimizer = torch.optim.Adam(model.classifier.parameters(), lr=1e-4)\n",
    "\n",
    "# Loss function for binary classification\n",
    "loss_fn = nn.BCELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76c9c0b-ff40-4b02-874d-864702060889",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in dataloader:\n",
    "    input_ids = batch['input_ids'].to(device)\n",
    "    attention_mask = batch['attention_mask'].to(device)\n",
    "    labels = batch['labels'].to(device).float()  # or .long() for multi-class\n",
    "\n",
    "    outputs = model(input_ids, attention_mask)\n",
    "\n",
    "    # Use appropriate loss\n",
    "    if model.is_binary:\n",
    "        loss_fn = nn.BCELoss()\n",
    "    else:\n",
    "        loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    loss = loss_fn(outputs.squeeze(), labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5afcb84-8238-4e8c-853c-897f020fb999",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import CamembertTokenizerFast, CamembertModel\n",
    "\n",
    "# Load pre-trained model and tokenizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "tokenizer = CamembertTokenizerFast.from_pretrained(\"camembert-base\")\n",
    "model = CamembertModel.from_pretrained(\"camembert-base\").to(device)\n",
    "model.eval()\n",
    "\n",
    "# Sample DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'text': [\n",
    "        \"J'aime le camembert !\",\n",
    "        \"Les chats dorment sur le canapé.\",\n",
    "        \"Il pleut souvent à Paris.\"\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Tokenize and encode all sentences at once\n",
    "inputs = tokenizer(\n",
    "    df['text'].tolist(),\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    return_tensors='pt',\n",
    "    return_attention_mask=True\n",
    ")\n",
    "\n",
    "# Move tensors to GPU\n",
    "input_ids = inputs['input_ids'].to(device)\n",
    "attention_mask = inputs['attention_mask'].to(device)\n",
    "\n",
    "# Generate embeddings (with no gradients)\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "# Extract sentence embeddings by averaging token embeddings (mean pooling)\n",
    "token_embeddings = outputs.last_hidden_state  # [batch_size, seq_len, hidden]\n",
    "sentence_embeddings = token_embeddings.mean(dim=1)  # [batch_size, hidden_dim]\n",
    "\n",
    "# Convert to CPU for further use\n",
    "sentence_embeddings_cpu = sentence_embeddings.cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6621ce-3541-4621-aeac-e884496f7d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add labels (for demonstration, you'll need to replace this with your own labels)\n",
    "df['label'] = [1, 0, 1]  # Example labels, modify accordingly\n",
    "\n",
    "# Features (sentence embeddings) and Labels\n",
    "X = sentence_embeddings_cpu  # Embeddings\n",
    "y = df['label'].values       # Labels (0 or 1)\n",
    "\n",
    "# Convert to tensors for PyTorch\n",
    "X_tensor = torch.tensor(X).float().to(device)\n",
    "y_tensor = torch.tensor(y).float().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3991004d-3c66-4e8f-b721-cc0e44411d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# Define your classifier (same as before)\n",
    "class CamembertSentenceClassifier(nn.Module):\n",
    "    def __init__(self, hidden_dim=768, mid_dim=256, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, mid_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(mid_dim, 1),      # Binary classification\n",
    "            nn.Sigmoid()                # Output in [0, 1]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.classifier(x)  # [batch_size, 1]\n",
    "\n",
    "# Initialize the model\n",
    "model = CamembertSentenceClassifier().to(device)\n",
    "\n",
    "# Loss function for binary classification\n",
    "loss_fn = nn.BCELoss()\n",
    "\n",
    "# Optimizer (only for the classifier layers)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# Training loop\n",
    "model.train()\n",
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = model(X_tensor)  # Shape: [batch_size, 1]\n",
    "    \n",
    "    # Compute loss\n",
    "    loss = loss_fn(outputs.squeeze(), y_tensor)\n",
    "\n",
    "    # Backpropagation\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Print loss\n",
    "    if (epoch + 1) % 2 == 0:\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {loss.item():.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
